{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.set_cmap('gray')\n",
    "\n",
    "\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "\n",
    "for impath in glob.glob('camera_cal/*'):\n",
    "    imdata_bgr = cv2.imread(impath)\n",
    "    imdata_gray = cv2.cvtColor(imdata_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    ret, corners = cv2.findChessboardCorners(imdata_gray, (9, 6))\n",
    "    if not ret:\n",
    "        print('Warning: Could not extract corners from chessboard'\n",
    "              f'image {impath}')\n",
    "        continue\n",
    "\n",
    "    imgpoints.append(corners)\n",
    "\n",
    "    objp = np.zeros((9 * 6, 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[:9, :6].T.reshape(-1, 2)\n",
    "    objpoints.append(objp)\n",
    "\n",
    "\n",
    "# all images are the same size, so use the shape of the last one\n",
    "imshape = imdata_gray.shape[::-1]\n",
    "ret, camera_mtx, camera_dist, _, _ = cv2.calibrateCamera(\n",
    "    objpoints, imgpoints, imshape, None, None)\n",
    "    \n",
    "if not ret:\n",
    "    raise Exception('Could not calibrate camera!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "imdata_bgr = cv2.imread('camera_cal/calibration1.jpg')\n",
    "imdata_gray = cv2.cvtColor(imdata_bgr, cv2.COLOR_BGR2GRAY)\n",
    "undistorted = cv2.undistort(\n",
    "    imdata_gray, camera_mtx, camera_dist, None, camera_mtx)\n",
    "cv2.imwrite('undistorted_example.jpg', undistorted)\n",
    "\n",
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 2))\n",
    "ax1.imshow(imdata_gray)\n",
    "ax1.set_title('Original')\n",
    "ax2.imshow(undistorted)\n",
    "ax2.set_title('Undistorted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from cached_property import cached_property\n",
    "import math\n",
    "\n",
    "def getattr_multi(obj, attrs):\n",
    "    rv = obj\n",
    "    for attr in attrs.split('.'):\n",
    "        rv = getattr(rv, attr)\n",
    "    return rv\n",
    "\n",
    "\n",
    "class ImageProcessor:\n",
    "    OUTPUT_IMGS = [\n",
    "        'undistorted',\n",
    "        'lane_lines',\n",
    "        'p.undistorted',\n",
    "        'p.lane_lines',\n",
    "    ]\n",
    "    SOBEL_MAX = 500\n",
    "\n",
    "    def __init__(self, path=None, img=None):\n",
    "        self.path = path\n",
    "        self._orig = img\n",
    "    \n",
    "    @cached_property\n",
    "    def base_img_name(self):\n",
    "        if self.path is None:\n",
    "            return 'noname'\n",
    "        return self.path.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    @property\n",
    "    def orig(self):\n",
    "        if self._orig is None:\n",
    "             self._orig = cv2.cvtColor(\n",
    "                 cv2.imread(self.path), cv2.COLOR_BGR2RGB)\n",
    "        return self._orig\n",
    "    \n",
    "    @cached_property\n",
    "    def gray(self):\n",
    "        return cv2.cvtColor(self.undistorted, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    @cached_property\n",
    "    def undistorted(self):\n",
    "        return cv2.undistort(self.orig, camera_mtx, camera_dist,\n",
    "                             None, camera_mtx)\n",
    "    \n",
    "    @cached_property\n",
    "    def fixed_perspective_transform_matrices(self):\n",
    "        # hardcoded input points gotten from looking at image in GIMP\n",
    "        src = np.float32([\n",
    "            [595, 450],  # top left\n",
    "            [685, 450],  # top right\n",
    "            [244, 686],  # bottom left\n",
    "            [1063, 686],  # bottom right\n",
    "        ])\n",
    "\n",
    "        margin_x = 200\n",
    "        margin_y = 0\n",
    "        size = 500\n",
    "        dst = np.float32([\n",
    "            [margin_x, margin_y],  # top left\n",
    "            [margin_x + size - 1, margin_y],  # top right\n",
    "            [margin_x, margin_y + size - 1],  # bottom left\n",
    "            [margin_x + size - 1, margin_y + size - 1],  # bottom right\n",
    "        ])\n",
    "\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "        out_dims = (size + margin_x * 2, size + margin_y * 2)\n",
    "        out_dims_inv = (self.orig.shape[1], self.orig.shape[0])\n",
    "        \n",
    "        return M, Minv, out_dims, out_dims_inv\n",
    "\n",
    "    def fixed_perspective_transform(self, img):\n",
    "        M = self.fixed_perspective_transform_matrices[0]\n",
    "        out_dims = self.fixed_perspective_transform_matrices[2]\n",
    "        \n",
    "        return cv2.warpPerspective(\n",
    "            img,\n",
    "            M,\n",
    "            out_dims,\n",
    "        )\n",
    "    \n",
    "    @cached_property\n",
    "    def saturation(self):\n",
    "        return cv2.cvtColor(self.undistorted, cv2.COLOR_RGB2HLS)[:,:,2]\n",
    "\n",
    "    def sobel(self, img, x, y):\n",
    "        sobel = cv2.Sobel(\n",
    "            img, cv2.CV_64F, x, y)\n",
    "        abs_sobel = np.abs(sobel)\n",
    "        scaled_sobel = 255 * np.clip(\n",
    "            abs_sobel / self.SOBEL_MAX,\n",
    "            0, 1)\n",
    "        return np.uint8(scaled_sobel)\n",
    "    \n",
    "    def sobel_mag(self, sobel_x, sobel_y):\n",
    "        return np.uint8(np.sqrt(\n",
    "            np.power(sobel_x, 2, dtype=np.float32)\n",
    "            + np.power(sobel_y, 2, dtype=np.float32)\n",
    "        ) / math.sqrt(2))\n",
    "\n",
    "    @cached_property\n",
    "    def gray_sobel_x(self):\n",
    "        return self.sobel(self.gray, 1, 0)\n",
    "    \n",
    "    @cached_property\n",
    "    def gray_sobel_y(self):\n",
    "        return self.sobel(self.gray, 0, 1)\n",
    "    \n",
    "    @cached_property\n",
    "    def gray_sobel_mag(self):\n",
    "        return self.sobel_mag(self.gray_sobel_x, self.gray_sobel_y)\n",
    "        \n",
    "    @cached_property\n",
    "    def sat_sobel_x(self):\n",
    "        return self.sobel(self.saturation, 1, 0)\n",
    "        \n",
    "    @cached_property\n",
    "    def sat_sobel_y(self):\n",
    "        return self.sobel(self.saturation, 0, 1)\n",
    "\n",
    "    @cached_property\n",
    "    def sat_sobel_mag(self):\n",
    "        return self.sobel_mag(self.sat_sobel_x, self.sat_sobel_y)\n",
    "    \n",
    "    def sobel_angle(self, img):\n",
    "        # angle of the gradient\n",
    "        # taken modulo pi so that e.g. up and to the right is the\n",
    "        # same as down and to the left\n",
    "        # 0 represents 0 rad, 255 represents pi rad\n",
    "        sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, 5)\n",
    "        sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, 5)\n",
    "        ang = np.arctan2(sobel_y, sobel_x)\n",
    "        ang = np.mod(ang, math.pi)\n",
    "        return np.uint8(ang * 255 / math.pi)\n",
    "    \n",
    "    def sobel_angle_thresh(self, img):\n",
    "        min_degrees = 30\n",
    "        max_degrees = 60\n",
    "        min_val = min_degrees * 255 / 180\n",
    "        max_val = max_degrees * 255 / 180\n",
    "        opp = 255 - img\n",
    "        binary_mask = (\n",
    "            (img > min_val)\n",
    "             & (img < max_val)\n",
    "            | (opp > min_val)\n",
    "               & (opp < max_val)\n",
    "        )\n",
    "        return np.uint8(binary_mask) * 255\n",
    "    \n",
    "    @cached_property\n",
    "    def gray_sobel_angle_thresh(self):\n",
    "        return self.sobel_angle_thresh(self.gray)\n",
    "\n",
    "    @cached_property\n",
    "    def sat_sobel_angle_thresh(self):\n",
    "        return self.sobel_angle_thresh(self.saturation)\n",
    "    \n",
    "    @cached_property\n",
    "    def combined_sobel_thresh(self):\n",
    "        gray_binary = (\n",
    "            (self.gray_sobel_x > 63)\n",
    "            & (self.gray_sobel_y > 63)\n",
    "            | self.gray_sobel_angle_thresh\n",
    "              & (self.gray_sobel_mag > 63)\n",
    "        )\n",
    "        sat_binary = (\n",
    "            (self.sat_sobel_x > 63)\n",
    "            & (self.sat_sobel_y > 63)\n",
    "            | self.sat_sobel_angle_thresh\n",
    "              & (self.sat_sobel_mag > 63)\n",
    "        )\n",
    "        binary = gray_binary | sat_binary\n",
    "        return np.uint8(255 * binary)\n",
    "\n",
    "    @cached_property\n",
    "    def yellow(self):\n",
    "        hsv = cv2.cvtColor(self.undistorted, cv2.COLOR_RGB2HSV)\n",
    "        h = hsv[:,:,0]\n",
    "        s = hsv[:,:,1]\n",
    "        binary = (15 <= h) & (h <= 30) & (s > 55)\n",
    "        return np.uint8(binary * 255)\n",
    "    \n",
    "    @cached_property\n",
    "    def white(self):\n",
    "        hsv = cv2.cvtColor(self.undistorted, cv2.COLOR_RGB2HSV)\n",
    "        s = hsv[:,:,1]\n",
    "        v = hsv[:,:,2]\n",
    "        binary = (s < 32) & (v >= 200) \n",
    "        return np.uint8(binary * 255)\n",
    "    \n",
    "    @cached_property\n",
    "    def y_or_w(self):\n",
    "        return self.yellow | self.white\n",
    "    \n",
    "    @property\n",
    "    def lane_lines(self):\n",
    "        return self.y_or_w\n",
    "\n",
    "    @property\n",
    "    def p(self_outer):\n",
    "        class PerspectiveTransformer:\n",
    "            def __getattr__(self, name):\n",
    "                return self_outer.fixed_perspective_transform(\n",
    "                    getattr(self_outer, name))\n",
    "\n",
    "        return PerspectiveTransformer()\n",
    "\n",
    "    def save(self):\n",
    "        for prop in self.OUTPUT_IMGS:\n",
    "            img = getattr_multi(self, prop)\n",
    "            \n",
    "            if len(img.shape) == 2:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "            else:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            prop = prop.replace('p.', 'perspective_')\n",
    "\n",
    "            cv2.imwrite(\n",
    "                f'output_images/{self.base_img_name}_{prop}.jpg',\n",
    "                img)\n",
    "\n",
    "\n",
    "all_images = sorted(glob.glob('test_images/*'))\n",
    "_, axes = plt.subplots(len(all_images), 3, figsize=(10, 20))\n",
    "\n",
    "for idx, path in enumerate(all_images):\n",
    "    imp = ImageProcessor(path)\n",
    "    axes[idx][0].imshow(imp.p.undistorted)\n",
    "    axes[idx][0].set_title(imp.base_img_name)\n",
    "    axes[idx][0].axis('off')\n",
    "    axes[idx][1].imshow(imp.p.lane_lines)\n",
    "    axes[idx][1].set_title('thresh using color')\n",
    "    axes[idx][1].axis('off')\n",
    "    axes[idx][2].imshow(imp.p.combined_sobel_thresh)\n",
    "    axes[idx][2].set_title('thresh using sobel')\n",
    "    axes[idx][2].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iterutils\n",
    "\n",
    "class LaneTracer(ImageProcessor):\n",
    "    OUTPUT_IMGS = ImageProcessor.OUTPUT_IMGS + [\n",
    "        'lane_points_viz',\n",
    "        'lane_coeffs_viz',\n",
    "        'lane_curvature_car_pos_viz',\n",
    "        'drivable_area_viz',\n",
    "    ]\n",
    "    N_WINDOWS = 10\n",
    "    WINDOW_WIDTH = 50\n",
    "    SEARCH_RADIUS = 100\n",
    "    # in straight_lines1, lane line centers are about 493 px apart\n",
    "    X_METERS_PER_PIX = 3.7 / 493\n",
    "    # in straight_lines1, dashed lane markers are about 55 px long\n",
    "    Y_METERS_PER_PIX = 3 / 55\n",
    "    \n",
    "    PRIOR_COEFFS_WEIGHT = 0.8\n",
    "\n",
    "    def __init__(self, *args, prior_coeffs=None, **kwargs):\n",
    "        self.prior_coeffs = prior_coeffs\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    @cached_property\n",
    "    def horiz_blur(self):\n",
    "        return cv2.GaussianBlur(\n",
    "            self.p.lane_lines, (2 * self.WINDOW_WIDTH - 1, 1), 0)\n",
    "    \n",
    "    @cached_property\n",
    "    def lane_points(self):\n",
    "        # calculate points that trace lanes from self.lane_lines using\n",
    "        # a sliding window search\n",
    "        # returns left_lane_points, right_lane_points in the\n",
    "        # perspective-transformed coordinate space\n",
    "        \n",
    "        # compute histogram of lower third of image\n",
    "        height, width = self.p.lane_lines.shape\n",
    "        window_height = height // self.N_WINDOWS\n",
    "        hist = np.sum(self.p.lane_lines[-height // 3:, :], axis=0)\n",
    "        \n",
    "        left_peak = np.argmax(hist[:width // 2])\n",
    "        right_peak = width // 2 + np.argmax(hist[width // 2:])\n",
    "        \n",
    "        # Note: in the lectures, np.convolve was used to find the\n",
    "        # position for each sliding window that maximized the number\n",
    "        # of active pixels it contained. Here, I'll simply use\n",
    "        # cv2.gaussianBlur to achieve roughly the same thing with\n",
    "        # a little less code.\n",
    "        horiz_blur = cv2.GaussianBlur(\n",
    "            self.p.lane_lines, (2 * self.WINDOW_WIDTH - 1, 1), 0)\n",
    "        \n",
    "        left_lane_points = [\n",
    "            (left_peak, None),  # will be removed\n",
    "        ]\n",
    "        right_lane_points = [\n",
    "            (right_peak, None),  # will be removed\n",
    "        ]\n",
    "        \n",
    "        for y in range(\n",
    "                height - window_height // 2, 0, -window_height):\n",
    "            for pts in [left_lane_points, right_lane_points]:\n",
    "                x_prev = pts[-1][0]\n",
    "                low = (\n",
    "                    x_prev\n",
    "                    - self.WINDOW_WIDTH // 2\n",
    "                    - self.SEARCH_RADIUS)\n",
    "                low = np.clip(low, 0, width)\n",
    "                high = (\n",
    "                    x_prev\n",
    "                    + self.WINDOW_WIDTH // 2\n",
    "                    + self.SEARCH_RADIUS)\n",
    "                high = np.clip(high, 0, width)\n",
    "                \n",
    "                rowhist = np.sum(\n",
    "                    horiz_blur[y - window_height // 2\n",
    "                               :y + window_height // 2,\n",
    "                               low:high], axis=0)\n",
    "                \n",
    "                maxpos = np.argmax(rowhist)\n",
    "                # only move if we detected enough pixels\n",
    "                if rowhist[maxpos] > 50:\n",
    "                    x = low + maxpos\n",
    "                else:\n",
    "                    x = x_prev\n",
    "\n",
    "                pts.append((x, y))\n",
    "        \n",
    "        return left_lane_points[1:], right_lane_points[1:]\n",
    "    \n",
    "    @cached_property\n",
    "    def lane_points_viz(self):\n",
    "        rv = np.copy(self.p.undistorted)\n",
    "        for pt in iterutils.flatten(self.lane_points):\n",
    "            cv2.circle(rv, pt, 10, (255, 0, 191), -1)\n",
    "        \n",
    "        return rv\n",
    "    \n",
    "    @cached_property\n",
    "    def lane_width_pix(self):\n",
    "        left_points, right_points = np.array(self.lane_points)\n",
    "        return np.mean(right_points[:, 0]) - np.mean(left_points[:, 0])\n",
    "\n",
    "    def combine_coeffs_with_prior(self, coeffs):\n",
    "        if not self.prior_coeffs:\n",
    "            return coeffs\n",
    "        \n",
    "        return (\n",
    "            np.array(self.prior_coeffs) * self.PRIOR_COEFFS_WEIGHT\n",
    "            + np.array(coeffs) * (1 - self.PRIOR_COEFFS_WEIGHT))\n",
    "\n",
    "    @cached_property\n",
    "    def lane_coeffs_raw(self):\n",
    "        # return A, B, and C in x = Ay^2 + By + C for the left and\n",
    "        # right lanes\n",
    "        \n",
    "        # assume that left and right lanes are parallel, fit a single\n",
    "        # quadratic to both of them\n",
    "        pts = np.array(self.lane_points, dtype=np.float32)\n",
    "        pts[1,:,0] -= self.lane_width_pix\n",
    "        pts = pts.reshape(-1, 2)\n",
    "        \n",
    "        left_fit = np.polyfit(pts[:,1], pts[:,0], 2)\n",
    "        right_fit = np.copy(left_fit)\n",
    "        right_fit[2] += self.lane_width_pix\n",
    "        \n",
    "        return left_fit, right_fit\n",
    "    \n",
    "    @cached_property\n",
    "    def lane_coeffs(self):\n",
    "        if self.prior_coeffs is None:\n",
    "            return self.lane_coeffs_raw\n",
    "        \n",
    "        return (\n",
    "            np.array(self.prior_coeffs) * self.PRIOR_COEFFS_WEIGHT\n",
    "            + np.array(self.lane_coeffs_raw) * (1 - self.PRIOR_COEFFS_WEIGHT))\n",
    "    \n",
    "    def draw_func_y(self, img, func, color=(255, 0, 191),\n",
    "                    thickness=5):\n",
    "        # draw a mathematical function on the image, defined as\n",
    "        # x = func(y)\n",
    "        x_prev = int(round(func(0)))\n",
    "        y_prev = 0\n",
    "        for y in range(10, img.shape[0], 10):\n",
    "            x = int(round(func(y)))\n",
    "            cv2.line(img, (x_prev, y_prev), (x, y), color, thickness)\n",
    "            x_prev = x\n",
    "            y_prev = y\n",
    "\n",
    "    @cached_property\n",
    "    def lane_coeffs_viz(self):\n",
    "        rv = np.copy(self.p.undistorted)\n",
    "\n",
    "        for coeffs in self.lane_coeffs:\n",
    "            A, B, C = coeffs\n",
    "            func = lambda y: A * y * y + B * y + C\n",
    "\n",
    "            self.draw_func_y(rv, func)\n",
    "        \n",
    "        return rv\n",
    "    \n",
    "    @cached_property\n",
    "    def curv_str(self):\n",
    "        if self.curvature_m >= 1e5:\n",
    "            return '>100k'\n",
    "        else:\n",
    "            return f'{self.curvature_m:5.0f}'\n",
    "\n",
    "    @cached_property\n",
    "    def pos_str(self):\n",
    "        return f'{self.center_offset_m:5.2f}'\n",
    "    \n",
    "    @cached_property\n",
    "    def lane_curvature_car_pos_viz(self):\n",
    "        rv = np.copy(self.lane_coeffs_viz)\n",
    "\n",
    "        cv2.putText(\n",
    "            rv,\n",
    "            self.curv_str,\n",
    "            (10, rv.shape[0] - 10),\n",
    "            cv2.FONT_HERSHEY_PLAIN,\n",
    "            2.5,  # fontScale\n",
    "            (255, 0, 191),\n",
    "            3,  # thickness\n",
    "            cv2.LINE_AA,  # lineType anti-aliased\n",
    "        )\n",
    "        \n",
    "        cv2.putText(\n",
    "            rv,\n",
    "            self.pos_str,\n",
    "            (rv.shape[1] - 130, rv.shape[0] - 10),\n",
    "            cv2.FONT_HERSHEY_PLAIN,\n",
    "            2.5,  # fontScale\n",
    "            (255, 0, 191),\n",
    "            3,  # thickness\n",
    "            cv2.LINE_AA,  # lineType anti-aliased\n",
    "        )\n",
    "        return rv\n",
    "\n",
    "    @cached_property\n",
    "    def curvature_m_using_ellipse(self):\n",
    "        # this doesn't quite work because the axes of the ellipse\n",
    "        # aren't exactly aligned with X and Y axes of image, esp\n",
    "        # when car isn't aimed straight down the lane\n",
    "        A, B, _ = self.lane_coeffs[0]\n",
    "        y = self.p.undistorted.shape[0]\n",
    "        curvature_p = (\n",
    "            (1 + (2 * A * y + B) ** 2) ** (3 / 2)\n",
    "            / abs(2 * A)\n",
    "        )\n",
    "        \n",
    "        # ellipse curvature formula\n",
    "        horiz_axis = curvature_p * self.X_METERS_PER_PIX\n",
    "        vert_axis = curvature_p * self.Y_METERS_PER_PIX\n",
    "        curvature_real = vert_axis ** 2 / horiz_axis\n",
    "        return curvature_real\n",
    "    \n",
    "    @cached_property\n",
    "    def curvature_m(self):\n",
    "        # calculate curvature in real-world coordinate space\n",
    "        pts = np.array(self.lane_points, dtype=np.float32)\n",
    "        lane_width = np.mean(pts[1,:,0] - pts[0,:,0])\n",
    "        pts[1,:,0] -= lane_width\n",
    "        pts = pts.reshape(-1, 2)\n",
    "        \n",
    "        pts[:, 0] *= self.X_METERS_PER_PIX\n",
    "        pts[:, 1] *= self.Y_METERS_PER_PIX\n",
    "        \n",
    "        A, B, _ = np.polyfit(pts[:, 1], pts[:, 0], 2)\n",
    "        y = self.p.undistorted.shape[0] * self.Y_METERS_PER_PIX\n",
    "\n",
    "        curvature_real = (\n",
    "            (1 + (2 * A * y + B) ** 2) ** (3 / 2)\n",
    "            / abs(2 * A)\n",
    "        )\n",
    "\n",
    "        return curvature_real\n",
    "    \n",
    "    @cached_property\n",
    "    def center_offset_m(self):\n",
    "        # negative means car is to the left of the center line, positive means car is to the right\n",
    "        car_center = self.lane_points_viz.shape[1] / 2\n",
    "        lane_center = self.lane_points[0][0][0] + self.lane_width_pix / 2\n",
    "        \n",
    "        return (car_center - lane_center) * self.X_METERS_PER_PIX\n",
    "\n",
    "    @cached_property\n",
    "    def drivable_area_viz(self):\n",
    "        viz_p = np.zeros_like(self.lane_coeffs_viz).astype(np.uint8)\n",
    "        \n",
    "        ys = np.array(\n",
    "            range(0, self.lane_coeffs_viz.shape[0] + 1, 10),\n",
    "            dtype=np.float32)\n",
    "        (Al, Bl, Cl), (Ar, Br, Cr) = self.lane_coeffs\n",
    "        xsl = Al * ys * ys + Bl * ys + Cl\n",
    "        xsr = Ar * ys * ys + Br * ys + Cr\n",
    "        \n",
    "        ys = list(ys) + list(reversed(ys))\n",
    "        xs = list(xsl) + list(reversed(xsr))\n",
    "        pts = np.vstack([xs, ys]).T.astype(np.int32)\n",
    "\n",
    "        cv2.fillConvexPoly(viz_p, pts, (0, 255, 0))\n",
    "        \n",
    "        Minv = self.fixed_perspective_transform_matrices[1]\n",
    "        out_dims_inv = self.fixed_perspective_transform_matrices[3]\n",
    "        \n",
    "        viz = cv2.warpPerspective(\n",
    "            viz_p,\n",
    "            Minv,\n",
    "            out_dims_inv,\n",
    "        )\n",
    "        \n",
    "        viz = cv2.addWeighted(self.undistorted, 1, viz, 0.3, 0)\n",
    "        \n",
    "        cv2.putText(\n",
    "            viz,\n",
    "            'Radius of curvature (m): ' + self.curv_str,\n",
    "            (10, 40),\n",
    "            cv2.FONT_HERSHEY_PLAIN,\n",
    "            2.5,  # fontScale\n",
    "            (255, 255, 204),\n",
    "            3,  # thickness\n",
    "            cv2.LINE_AA,  # lineType anti-aliased\n",
    "        )\n",
    "        \n",
    "        cv2.putText(\n",
    "            viz,\n",
    "            'Offset from center (m): ' + self.pos_str,\n",
    "            (10, 80),\n",
    "            cv2.FONT_HERSHEY_PLAIN,\n",
    "            2.5,  # fontScale\n",
    "            (255, 255, 204),\n",
    "            3,  # thickness\n",
    "            cv2.LINE_AA,  # lineType anti-aliased\n",
    "        )\n",
    "\n",
    "        return viz\n",
    "\n",
    "\n",
    "_, axes = plt.subplots(len(all_images), 2, figsize=(10, 20))\n",
    "\n",
    "for idx, path in enumerate(all_images):\n",
    "    lt = LaneTracer(path)\n",
    "    axes[idx][0].imshow(lt.lane_curvature_car_pos_viz)\n",
    "    axes[idx][0].set_title(lt.base_img_name)\n",
    "    axes[idx][0].axis('off')\n",
    "    axes[idx][1].imshow(lt.drivable_area_viz)\n",
    "    axes[idx][1].set_title(lt.base_img_name)\n",
    "    axes[idx][1].axis('off')\n",
    "    lt.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "prior_coeffs = None\n",
    "def process(frame):\n",
    "    global prior_coeffs\n",
    "    lt = LaneTracer(img=frame, prior_coeffs=prior_coeffs)\n",
    "    prior_coeffs = lt.lane_coeffs\n",
    "    return lt.drivable_area_viz\n",
    "\n",
    "inclip = VideoFileClip('project_video.mp4')\n",
    "outclip = inclip.fl_image(process)\n",
    "%time outclip.write_videofile('outvid.mp4', audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
